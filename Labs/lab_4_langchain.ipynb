{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lab, the `azure-cosmos` library was used to perform a vector search through a db command to find product documents that were most similar to the user's input. LangChain has a vector store class named [**AzureCosmosDBNoSqlVectorSearch**](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/vectorstores/azure_cosmos_db_no_sql.ipynb), that supports vector search in Azure Cosmos DB for NoSQL. However, at the time of this writing, due to the pace of LangChain development, the current implementation has a bug that impacts the retrieval of search results. As such, the code in this lab will create a LangChain [retriever class](https://python.langchain.com/docs/integrations/retrievers/) to connect to and search the vector store using the `azure-cosmos` library. More on retrievers in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pydantic import BaseModel\n",
    "from typing import Type, TypeVar, List\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from azure.cosmos import CosmosClient, ContainerProxy\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForRetrieverRun,\n",
    "    CallbackManagerForRetrieverRun,\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from models import Product, SalesOrder\n",
    "\n",
    "T = TypeVar('T', bound=BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load settings for the notebook\n",
    "load_dotenv()\n",
    "CONNECTION_STRING = os.environ.get(\"COSMOS_DB_CONNECTION_STRING\")\n",
    "EMBEDDINGS_DEPLOYMENT_NAME = \"embeddings\"\n",
    "COMPLETIONS_DEPLOYMENT_NAME = \"completions\"\n",
    "AOAI_ENDPOINT = os.environ.get(\"AOAI_ENDPOINT\")\n",
    "AOAI_KEY = os.environ.get(\"AOAI_KEY\")\n",
    "AOAI_API_VERSION = \"2024-06-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Azure OpenAI connectivity\n",
    "llm = AzureChatOpenAI(            \n",
    "        temperature = 0,\n",
    "        openai_api_version = AOAI_API_VERSION,\n",
    "        azure_endpoint = AOAI_ENDPOINT,\n",
    "        openai_api_key = AOAI_KEY,         \n",
    "        azure_deployment = \"completions\"\n",
    ")\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    openai_api_version = AOAI_API_VERSION,\n",
    "    azure_endpoint = AOAI_ENDPOINT,\n",
    "    openai_api_key = AOAI_KEY,   \n",
    "    azure_deployment = \"embeddings\",\n",
    "    chunk_size=800\n",
    ")\n",
    "\n",
    "# Initialize the Azure Cosmos DB client, database and product (with vector) container\n",
    "client = CosmosClient.from_connection_string(CONNECTION_STRING)\n",
    "db = client.get_database_client(\"cosmic_works\")\n",
    "product_v_container = db.get_container_client(\"product_v\")\n",
    "sales_order_container = db.get_container_client(\"salesOrder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with LangChain\n",
    "\n",
    "Recall that in previous labs the `products_v` container was created with an indexing policy and vector embedding policy to enable vector search. Each item in the container contains a contentVector field that contains the vectorized embeddings of the document itself.\n",
    "\n",
    "In this section, we'll implement the RAG pattern using LangChain. In LangChain, a **retriever** is used to augment the prompt with contextual data. In this case, a custom LangChain retriever is needed. The return value of the invokation of retriever in LangChain is a list of `Document` objects. The LangChain `Document` class contains two properties: `page_content`, that represents the textual content that is typically used to augment the prompt, and `metadata` that contains all other attributes of the document. In this case, we'll use the document content as the `page_content` and include the similarity score as the metadata.\n",
    "\n",
    "We'll also define a reusable RAG [chain](https://python.langchain.com/docs/modules/chains/) to control the flow and behavior of the call into the LLM. This chain is defined using the LCEL syntax (LangChain Expression Language)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzureCosmosDBNoSQLRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    A custom LangChain retriever that uses Azure Cosmos DB NoSQL database for vector search.\n",
    "    \"\"\"\n",
    "    embedding_model: AzureOpenAIEmbeddings\n",
    "    container: ContainerProxy\n",
    "    model: Type[T]\n",
    "    vector_field_name: str\n",
    "    num_results: int=5\n",
    "\n",
    "    def __get_embeddings(self, text: str) -> List[float]:       \n",
    "        \"\"\"\n",
    "        Returns embeddings vector for a given text.\n",
    "        \"\"\"\n",
    "        embedding = self.embedding_model.embed_query(text)        \n",
    "        time.sleep(0.5) # rest period to avoid rate limiting on AOAI\n",
    "        return embedding\n",
    "    \n",
    "    def __get_item_by_id(self, id) -> T:\n",
    "        \"\"\"\n",
    "        Retrieves a single item from the Azure Cosmos DB NoSQL database by its ID.\n",
    "        \"\"\"\n",
    "        query = \"SELECT * FROM itm WHERE itm.id = @id\"\n",
    "        parameters = [\n",
    "            {\"name\": \"@id\", \"value\": id}\n",
    "        ]    \n",
    "        item = list(self.container.query_items(\n",
    "            query=query,\n",
    "            parameters=parameters,\n",
    "            enable_cross_partition_query=True\n",
    "        ))[0]\n",
    "        return self.model(**item)\n",
    "    \n",
    "    def __delete_attribute_by_alias(self, instance: BaseModel, alias):\n",
    "        for model_field in instance.model_fields:\n",
    "            field = instance.model_fields[model_field]            \n",
    "            if field.alias == alias:\n",
    "                delattr(instance, model_field)\n",
    "                return\n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Performs a synchronous vector search on the Azure Cosmos DB NoSQL database.\n",
    "        \"\"\"\n",
    "        embedding = self.__get_embeddings(query)\n",
    "        items = self.container.query_items(\n",
    "            query=f\"\"\"SELECT TOP @num_results itm.id, VectorDistance(itm.{self.vector_field_name}, @embedding) AS SimilarityScore \n",
    "                    FROM itm\n",
    "                    ORDER BY VectorDistance(itm.{self.vector_field_name}, @embedding)\n",
    "                    \"\"\",\n",
    "            parameters = [\n",
    "                { \"name\": \"@num_results\", \"value\": self.num_results },\n",
    "                { \"name\": \"@embedding\", \"value\": embedding }            \n",
    "            ],\n",
    "            enable_cross_partition_query=True\n",
    "        ) \n",
    "        returned_docs = []\n",
    "        for item in items:\n",
    "            itm = self.__get_item_by_id(item[\"id\"])  \n",
    "            # Remove the vector field from the returned item so it doesn't fill the context window\n",
    "            self.__delete_attribute_by_alias(itm, self.vector_field_name)            \n",
    "            returned_docs.append(Document(page_content=json.dumps(itm, indent=4, default=str), metadata={\"similarity_score\": item[\"SimilarityScore\"]}))\n",
    "        return returned_docs\n",
    "    \n",
    "    async def _aget_relevant_documents(\n",
    "        self, query: str, *, run_manager: AsyncCallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Performs an asynchronous vector search on the Azure Cosmos DB NoSQL database.        \n",
    "        \"\"\"\n",
    "        raise Exception(f\"Asynchronous search not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_retriever = AzureCosmosDBNoSQLRetriever(\n",
    "    embedding_model = embedding_model,\n",
    "    container = product_v_container,\n",
    "    model = Product,\n",
    "    vector_field_name = \"contentVector\",\n",
    "    num_results = 5   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What yellow products are there?\"\n",
    "products_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A system prompt describes the responsibilities, instructions, and persona of the AI.\n",
    "# Note the addition of the templated variable/placeholder for the list of products and the incoming question.\n",
    "system_prompt = \"\"\"\n",
    "Your name is \"Willie\". You are an AI assistant for the Cosmic Works bike store. You help people find production information for bikes and accessories. Your demeanor is friendly, playful with lots of energy.\n",
    "\n",
    "Do not include citations or citation numbers in your responses. Do not include emojis.\n",
    "\n",
    "Only answer questions related to the information provided in the list of products below that are represented\n",
    "in JSON format.\n",
    "\n",
    "If you are asked a question that is not in the list, respond with \"I don't know.\"\n",
    "\n",
    "Only answer questions related to Cosmic Works products, customers, and sales orders.\n",
    "\n",
    "If a question is not related to Cosmic Works products, customers, or sales orders,\n",
    "respond with \"I only answer questions about Cosmic Works\"\n",
    "\n",
    "List of products:\n",
    "{products}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt template from the system_prompt text\n",
    "llm_prompt = PromptTemplate.from_template(system_prompt)\n",
    "\n",
    "rag_chain = (\n",
    "    # populate the tokens/placeholders in the llm_prompt    \n",
    "    # question is a passthrough that takes the incoming question\n",
    "    { \"products\": products_retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    # pass the populated prompt to the language model\n",
    "    | llm\n",
    "    # return the string ouptut from the language model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the names and skus of yellow products? Output the answer as a bulleted list.\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the concept of an agent is quite similar to that of a chain in LangChain but with one fundamental difference. A chain in LangChain is a hard-coded sequence of steps executed in a specific order. Conversely, an agent leverages the LLM to assess the incoming request with the current context to decide what steps or actions need to be executed and in what order.\n",
    "\n",
    "LangChain agents can leverage tools and toolkits. A tool can be an integration into an external system, custom code, a retriever, or even another chain. A toolkit is a collection of tools that can be used to solve a specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create Agent Tools\n",
    " \n",
    " LangChain does have a built-in [`create_retriever_tool`](https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents#retriever-tool) that wraps a vector store retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool that will use the product vector search in Azure Cosmos DB for NoSQL\n",
    "products_retriever_tool = create_retriever_tool(\n",
    "    retriever = products_retriever,\n",
    "    name = \"vector_search_products\",\n",
    "    description = \"Searches Cosmic Works product information for similar products based on the question. Returns the product information in JSON format.\"\n",
    ")\n",
    "tools = [products_retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools part 2\n",
    "\n",
    "Certain properties do not have semantic meaning (such as the GUID id field) and attempting to use vector search on these fields will not yield meaningful results. We need a tool to retrieve specific documents based on popular searches criteria.\n",
    "\n",
    "The following tool definitions is not an exhaustive list of what may be needed but serves as an example to provide concrete lookups of a document in the Cosmic Works database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools helper methods\n",
    "def delete_attribute_by_alias(instance: BaseModel, alias:str):\n",
    "    for model_field in instance.model_fields:\n",
    "        field = instance.model_fields[model_field]            \n",
    "        if field.alias == alias:\n",
    "            delattr(instance, model_field)\n",
    "            return\n",
    "\n",
    "def get_single_item_by_field_name(\n",
    "        container:ContainerProxy, \n",
    "        field_name:str, \n",
    "        field_value:str, \n",
    "        model:Type[T]) -> T:\n",
    "    \"\"\"\n",
    "    Retrieves a single item from the Azure Cosmos DB NoSQL database by a specific field and value.\n",
    "    \"\"\"\n",
    "    query = f\"SELECT TOP 1 * FROM itm WHERE itm.{field_name} = @value\"\n",
    "    parameters = [\n",
    "        {\n",
    "            \"name\": \"@value\", \n",
    "            \"value\": field_value\n",
    "        }\n",
    "    ]    \n",
    "    item = list(container.query_items(\n",
    "        query=query,\n",
    "        parameters=parameters,\n",
    "        enable_cross_partition_query=True\n",
    "    ))[0]\n",
    "    item_casted = model(**item)    \n",
    "    return item_casted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_by_id(product_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves a product by its ID.    \n",
    "    \"\"\"\n",
    "    item = get_single_item_by_field_name(product_v_container, \"id\", product_id, Product)\n",
    "    delete_attribute_by_alias(item, \"contentVector\")\n",
    "    return json.dumps(item, indent=4, default=str)    \n",
    "\n",
    "def get_product_by_sku(sku: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves a product by its sku.\n",
    "    \"\"\"\n",
    "    item = get_single_item_by_field_name(product_v_container, \"sku\", sku, Product)\n",
    "    delete_attribute_by_alias(item, \"contentVector\")\n",
    "    return json.dumps(item, indent=4, default=str)\n",
    "    \n",
    "def get_sales_by_id(sales_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves a sales order by its ID.\n",
    "    \"\"\"\n",
    "    item = get_single_item_by_field_name(sales_order_container, \"id\", sales_id, SalesOrder)\n",
    "    return json.dumps(item, indent=4, default=str)\n",
    "\n",
    "tools.extend([\n",
    "    StructuredTool.from_function(get_product_by_id),\n",
    "    StructuredTool.from_function(get_product_by_sku),\n",
    "    StructuredTool.from_function(get_sales_by_id)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the agent\n",
    "\n",
    "The [`create_openai_functions_agent`](https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents#agent-constructor) is a built-in agent that includes conversational history, tools selection, and agent scratchpad (for keeping track of the state of the progress of the LLM interaction).\n",
    "\n",
    "Remember that an agent leverages the LLM to assess the incoming request with the current context to decide what steps or actions need to be executed and in what order. LangChain agents can leverage tools. A tool can be an integration into an external system, custom code, or even another chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_instructions = \"\"\"           \n",
    "        Your name is \"Willie\". You are an AI assistant for the Cosmic Works bike store. You help people find production information for bikes and accessories. Your demeanor is friendly, playful with lots of energy.\n",
    "        Do not include citations or citation numbers in your responses. Do not include emojis.\n",
    "        You are designed to answer questions about the products that Cosmic Works sells, the customers that buy them, and the sales orders that are placed by customers.\n",
    "        If you don't know the answer to a question, respond with \"I don't know.\"      \n",
    "        Only answer questions related to Cosmic Works products, customers, and sales orders.\n",
    "        If a question is not related to Cosmic Works products, customers, or sales orders,\n",
    "        respond with \"I only answer questions about Cosmic Works\"\n",
    "    \"\"\"  \n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", agent_instructions),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")  \n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: On the following agent_executor invocations it is safe to ignore the error: `Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")` - this is a defect in the verbose debug output of LangChain and does not affect the outcome of the invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": \"What products do you have that are yellow?\"})\n",
    "print(\"***********************************************************\")\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": \"What products were purchased for sales order '06FE91D2-B350-471A-AD29-906BF4EB97C4' ?\"})\n",
    "print(\"***********************************************************\")\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": \"What was the sales order total for sales order '93436616-4C8A-407D-9FDA-908707EFA2C5' ?\"})\n",
    "print(\"***********************************************************\")\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": \"What was the price of the product with sku `FR-R92B-58` ?\"})\n",
    "print(\"***********************************************************\")\n",
    "print(result['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
