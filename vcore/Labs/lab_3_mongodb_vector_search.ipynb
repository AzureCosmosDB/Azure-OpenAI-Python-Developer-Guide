{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search using vCore-based Azure Cosmos DB for MongoDB\n",
    "\n",
    "This notebook demonstrates using an Azure OpenAI embedding model to vectorize documents already stored in Azure Cosmos DB API for MongoDB, storing the embedding vectors and the creation of a vector index. Lastly, the notebook will demonstrate how to query the vector index to find similar documents.\n",
    "\n",
    "This lab expects the data that was loaded in Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymongo\n",
    "import time\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load settings\n",
    "\n",
    "This lab expects the `.env` file that was created in Lab 1 to obtain the connection string for the database.\n",
    "\n",
    "Add the following entries into the `.env` file to support the connection to Azure OpenAI API, replacing the values for `<your key>` and `<your endpoint>` with the values from your Azure OpenAI API resource.\n",
    "\n",
    "```text\n",
    "AOAI_ENDPOINT=\"<your endpoint>\"\n",
    "AOAI_KEY=\"<your key>\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CONNECTION_STRING = os.environ.get(\"DB_CONNECTION_STRING\")\n",
    "EMBEDDINGS_DEPLOYMENT_NAME = \"embeddings\"\n",
    "COMPLETIONS_DEPLOYMENT_NAME = \"completions\"\n",
    "AOAI_ENDPOINT = os.environ.get(\"AOAI_ENDPOINT\")\n",
    "AOAI_KEY = os.environ.get(\"AOAI_KEY\")\n",
    "AOAI_API_VERSION = \"2023-05-15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish connectivity to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = pymongo.MongoClient(CONNECTION_STRING)\n",
    "# Create database to hold cosmic works data\n",
    "# MongoDB will create the database if it does not exist\n",
    "db = db_client.cosmic_works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Azure OpenAI connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client = AzureOpenAI(\n",
    "    azure_endpoint = AOAI_ENDPOINT,\n",
    "    api_version = AOAI_API_VERSION,\n",
    "    api_key = AOAI_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize and store the embeddings in each document\n",
    "\n",
    "The process of creating a vector embedding field on each document only needs to be done once. However, if a document changes, the vector embedding field will need to be updated with an updated vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(3))\n",
    "def generate_embeddings(text: str):\n",
    "    '''\n",
    "    Generate embeddings from string of text using the deployed Azure OpenAI API embeddings model.\n",
    "    This will be used to vectorize document data and incoming user messages for a similarity search with\n",
    "    the vector index.\n",
    "    '''\n",
    "    response = ai_client.embeddings.create(input=text, model=EMBEDDINGS_DEPLOYMENT_NAME)\n",
    "    embeddings = response.data[0].embedding\n",
    "    time.sleep(0.5) # rest period to avoid rate limiting on AOAI\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate embeddings generation using a test string\n",
    "test = \"hello, world\"\n",
    "print(generate_embeddings(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize and update all documents in the Cosmic Works database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_collection_content_vector_field(collection_name: str):\n",
    "    '''\n",
    "    Add a new field to the collection to hold the vectorized content of each document.\n",
    "    '''\n",
    "    collection = db[collection_name]\n",
    "    bulk_operations = []\n",
    "    for doc in collection.find():\n",
    "        # remove any previous contentVector embeddings\n",
    "        if \"contentVector\" in doc:\n",
    "            del doc[\"contentVector\"]\n",
    "\n",
    "        # generate embeddings for the document string representation\n",
    "        content = json.dumps(doc, default=str)\n",
    "        content_vector = generate_embeddings(content)       \n",
    "        \n",
    "        bulk_operations.append(pymongo.UpdateOne(\n",
    "            {\"_id\": doc[\"_id\"]},\n",
    "            {\"$set\": {\"contentVector\": content_vector}},\n",
    "            upsert=True\n",
    "        ))\n",
    "    # execute bulk operations\n",
    "    collection.bulk_write(bulk_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vector field to products documents - this will take approximately 3-5 minutes due to rate limiting\n",
    "add_collection_content_vector_field(\"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vector field to customers documents - this will take approximately 1-2 minutes due to rate limiting\n",
    "add_collection_content_vector_field(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vector field to customers documents - this will take approximately 15-20 minutes due to rate limiting\n",
    "add_collection_content_vector_field(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the products vector index\n",
    "db.command({\n",
    "  'createIndexes': 'products',\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'VectorSearchIndex',\n",
    "      'key': {\n",
    "        \"contentVector\": \"cosmosSearch\"\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-ivf',\n",
    "        'numLists': 1,\n",
    "        'similarity': 'COS',\n",
    "        'dimensions': 1536\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})\n",
    "\n",
    "# Create the customers vector index\n",
    "db.command({\n",
    "  'createIndexes': 'customers',\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'VectorSearchIndex',\n",
    "      'key': {\n",
    "        \"contentVector\": \"cosmosSearch\"\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-ivf',\n",
    "        'numLists': 1,\n",
    "        'similarity': 'COS',\n",
    "        'dimensions': 1536\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})\n",
    "\n",
    "# Create the sales vector index\n",
    "db.command({\n",
    "  'createIndexes': 'sales',\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'VectorSearchIndex',\n",
    "      'key': {\n",
    "        \"contentVector\": \"cosmosSearch\"\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-ivf',\n",
    "        'numLists': 1,\n",
    "        'similarity': 'COS',\n",
    "        'dimensions': 1536\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use vector search in vCore-based Azure Cosmos DB for MongoDB\n",
    "\n",
    "Now that each document has its associated vector embedding and the vector indexes have been created on each collection, we can now use the vector search capabilities of vCore-based Azure Cosmos DB for MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(collection_name, query, num_results=3):\n",
    "    \"\"\"\n",
    "    Perform a vector search on the specified collection by vectorizing\n",
    "    the query and searching the vector index for the most similar documents.\n",
    "\n",
    "    returns a list of the top num_results most similar documents\n",
    "    \"\"\"\n",
    "    collection = db[collection_name]\n",
    "    query_embedding = generate_embeddings(query)    \n",
    "    pipeline = [\n",
    "        {\n",
    "            '$search': {\n",
    "                \"cosmosSearch\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"path\": \"contentVector\",\n",
    "                    \"k\": num_results\n",
    "                },\n",
    "                \"returnStoredSource\": True }},\n",
    "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' } }\n",
    "    ]\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return results\n",
    "\n",
    "def print_product_search_result(result):\n",
    "    '''\n",
    "    Print the search result document in a readable format\n",
    "    '''\n",
    "    print(f\"Similarity Score: {result['similarityScore']}\")  \n",
    "    print(f\"Name: {result['document']['name']}\")   \n",
    "    print(f\"Category: {result['document']['categoryName']}\")\n",
    "    print(f\"SKU: {result['document']['categoryName']}\")\n",
    "    print(f\"_id: {result['document']['_id']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What bikes do you have?\"\n",
    "results = vector_search(\"products\", query, num_results=4)\n",
    "for result in results:\n",
    "    print_product_search_result(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What do you have that is yellow?\"\n",
    "results = vector_search(\"products\", query, num_results=4)\n",
    "for result in results:\n",
    "    print_product_search_result(result)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use vector search results in a RAG pattern with Chat GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A system prompt describes the responsibilities, instructions, and persona of the AI.\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful, fun and friendly sales assistant for Cosmic Works, a bicycle and bicycle accessories store. \n",
    "Your name is Cosmo.\n",
    "You are designed to answer questions about the products that Cosmic Works sells.\n",
    "\n",
    "Only answer questions related to the information provided in the list of products below that are represented\n",
    "in JSON format.\n",
    "\n",
    "If you are asked a question that is not in the list, respond with \"I don't know.\"\n",
    "\n",
    "List of products:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_vector_search(question: str, num_results: int = 3):\n",
    "    \"\"\"\n",
    "    Use the RAG model to generate a prompt using vector search results based on the\n",
    "    incoming question.  \n",
    "    \"\"\"\n",
    "    # perform the vector search and build product list\n",
    "    results = vector_search(\"products\", question, num_results=num_results)\n",
    "    product_list = \"\"\n",
    "    for result in results:\n",
    "        if \"contentVector\" in result[\"document\"]:\n",
    "            del result[\"document\"][\"contentVector\"]\n",
    "        product_list += json.dumps(result[\"document\"], indent=4, default=str) + \"\\n\\n\"\n",
    "\n",
    "    # generate prompt for the LLM with vector results\n",
    "    formatted_prompt = system_prompt + product_list\n",
    "\n",
    "    # prepare the LLM request\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    completion = ai_client.chat.completions.create(messages=messages, model=COMPLETIONS_DEPLOYMENT_NAME)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_with_vector_search(\"What bikes do you have?\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_with_vector_search(\"What are the names and skus of yellow products?\", 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
